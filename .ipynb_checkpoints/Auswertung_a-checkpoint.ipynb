{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c17fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "maerchen = \"\"  #25 Eine leere Zeichenkette, in der Daten für Märchen gesammelt werden.\n",
    "import xml.etree.ElementTree as ET  #26 Importieren der ElementTree-Bibliothek zum Parsen von XML.\n",
    "root_node = ET.parse('gesamt_märchen.xml').getroot()  #27 Parsen der XML-Datei und Zugriff auf das Wurzelelement.\n",
    "never_saved = True  #28 Ein boolean-Wert, der angibt, ob Daten bereits gespeichert wurden oder nicht.\n",
    "#29 Iteration durch jedes 'text'-Element in der XML-Datei.\n",
    "for corp in root_node.findall (\".//{http://www.tei-c.org/ns/1.0}teiCorpus\"):\n",
    "    if \"xtk\" in corp.attrib[\"n\"]:\n",
    "        for ganze in corp.findall(\".//{http://www.tei-c.org/ns/1.0}text\"):\n",
    "            #30 Überprüfung, ob das Attribut 'deu' in der 'id'-Eigenschaft des 'text'-Elements vorhanden ist.\n",
    "            if ('zyx_' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']):\n",
    "                #31 Iteration durch jeden Absatz im 'body' des 'text'-Elements.\n",
    "                for body in ganze.findall(\".//{http://www.tei-c.org/ns/1.0}body\"):\n",
    "                    for absatz in body.findall(\".//{http://www.tei-c.org/ns/1.0}p\"):\n",
    "                        #32 Iteration durch jede 'seg'-Phrase im Absatz.\n",
    "                        for phrase in absatz.findall(\".//{http://www.tei-c.org/ns/1.0}seg\"):\n",
    "                            #33 Extrahieren von Labels und Inhalten aus den Attributen und dem Text der Phrase.\n",
    "                            labelx = ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "                            labela = phrase.attrib['{www.dglab.uni-jena.de/vmf/a}ana']\n",
    "                            if labela.startswith ('a'):# and labela !=\"a554\":\n",
    "\n",
    "                                maerchen += labela+','+labelx+'\\n'\n",
    "                                \n",
    "with open(\"anzahl.csv\", 'w', encoding='utf-8') as f:\n",
    "    f.write ('labela,labelx\\n')\n",
    "    f.write (maerchen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95976700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "ava.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"ava.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25bf5e8c050>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from pyvis.network import Network\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# CSV-Datei einlesen\n",
    "df = pd.read_csv('anzahl.csv')\n",
    "\n",
    "# Duplikate entfernen, um einzigartige Datensätze zu erhalten\n",
    "unique_df = df.drop_duplicates()\n",
    "\n",
    "# Netzwerk erstellen\n",
    "net = Network(notebook=True)\n",
    "net.force_atlas_2based()\n",
    "\n",
    "# Dictionary zur Speicherung der Kanten, deren Gewicht und der zugehörigen labelx-Werte\n",
    "edges = {}\n",
    "min_frequency = 1\n",
    "min_unique_labelx = 1\n",
    "self_loops = {}\n",
    "node_frequency = defaultdict(set)\n",
    "\n",
    "# Schritt 1: Parsen der XSD-Datei\n",
    "xsd_path = 'kf/vmf_a.xsd'\n",
    "tree = ET.parse(xsd_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Namespace für XSD\n",
    "ns = {'xs': 'http://www.w3.org/2001/XMLSchema'}\n",
    "\n",
    "# Dictionary zur Speicherung der ersetzten Werte\n",
    "replacement_dict = {}\n",
    "\n",
    "# Value-Werte mit Leerzeichen extrahieren und speichern\n",
    "for enumeration in root.findall(\".//xs:enumeration\", ns):\n",
    "    value = enumeration.attrib.get('value', '')\n",
    "    if ' ' in value:  # Werte mit Leerzeichen\n",
    "        split_value = value.split(' ', 1)  # Split bei erstem Leerzeichen\n",
    "        key = split_value[0]\n",
    "        full_value = value\n",
    "        replacement_dict[key] = full_value\n",
    "\n",
    "# Gruppieren nach labelx und zählen, wie viele einzigartige labelx-Werte mit jedem labela verbunden sind\n",
    "for labelx, group in unique_df.groupby('labelx'):\n",
    "    labelas = group['labela'].unique()\n",
    "    \n",
    "    if len(labelas) == 1:\n",
    "        labela = labelas[0]\n",
    "        if labela in self_loops:\n",
    "            self_loops[labela]['weight'] += 1\n",
    "            self_loops[labela]['labelx_values'].append(labelx)\n",
    "        else:\n",
    "            self_loops[labela] = {'weight': 1, 'labelx_values': [labelx]}\n",
    "        node_frequency[labela].add(labelx)\n",
    "    else:\n",
    "        for pair in combinations(labelas, 2):\n",
    "            sorted_pair = tuple(sorted(pair))\n",
    "            if sorted_pair in edges:\n",
    "                edges[sorted_pair]['weight'] += 1\n",
    "                edges[sorted_pair]['labelx_values'].append(labelx)\n",
    "            else:\n",
    "                edges[sorted_pair] = {'weight': 1, 'labelx_values': [labelx]}\n",
    "            node_frequency[pair[0]].add(labelx)\n",
    "            node_frequency[pair[1]].add(labelx)\n",
    "\n",
    "# Berechne die Häufigkeit basierend auf der Anzahl der einzigartigen labelx-Werte\n",
    "node_frequency = {node: len(labelx_set) for node, labelx_set in node_frequency.items()}\n",
    "\n",
    "# Funktion zur Skalierung der Knotengröße\n",
    "def get_node_size(frequency, min_size=10, max_size=50):\n",
    "    max_frequency = max(node_frequency.values()) if node_frequency else 1\n",
    "    return min_size + (max_size - min_size) * (frequency / max_frequency)\n",
    "\n",
    "# Schritt 3: Knoten und Kanten hinzufügen\n",
    "for (labela1, labela2), data in edges.items():\n",
    "    if data['weight'] >= min_frequency:\n",
    "        if node_frequency[labela1] >= min_unique_labelx and node_frequency[labela2] >= min_unique_labelx:\n",
    "            # Ersetzung im Titel, falls im replacement_dict vorhanden\n",
    "            title1 = replacement_dict.get(labela1, labela1)\n",
    "            title2 = replacement_dict.get(labela2, labela2)\n",
    "            \n",
    "            size1 = get_node_size(node_frequency[labela1])\n",
    "            size2 = get_node_size(node_frequency[labela2])\n",
    "            \n",
    "            net.add_node(labela1, labela1, title=f'{title1} ({node_frequency[labela1]})', size=size1)\n",
    "            net.add_node(labela2, labela2, title=f'{title2} ({node_frequency[labela2]})', size=size2)\n",
    "            net.add_edge(labela1, labela2, value=data['weight'])\n",
    "\n",
    "# Selbstverbindungen hinzufügen\n",
    "for labela, data in self_loops.items():\n",
    "    if node_frequency[labela] >= min_unique_labelx:\n",
    "        title = replacement_dict.get(labela, labela)\n",
    "        size = get_node_size(node_frequency[labela])\n",
    "        net.add_node(labela, labela, title=f'{title} ({node_frequency[labela]})', size=size)\n",
    "        net.add_edge(labela, labela, value=data['weight'])\n",
    "\n",
    "# Graph anzeigen\n",
    "net.show('ava.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374f3c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "ava.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"ava.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25be62b2550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from pyvis.network import Network\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# CSV-Datei einlesen\n",
    "df = pd.read_csv('anzahl.csv')\n",
    "\n",
    "# Duplikate entfernen, um einzigartige Datensätze zu erhalten\n",
    "unique_df = df.drop_duplicates()\n",
    "\n",
    "# Netzwerk erstellen\n",
    "net = Network(notebook=True)\n",
    "net.force_atlas_2based()\n",
    "\n",
    "# Dictionary zur Speicherung der Kanten, deren Gewicht und der zugehörigen labelx-Werte\n",
    "edges = {}\n",
    "min_frequency = 1\n",
    "min_unique_labelx = 1\n",
    "self_loops = {}\n",
    "node_frequency = defaultdict(set)\n",
    "\n",
    "# Schritt 1: Parsen der XSD-Datei\n",
    "xsd_path = 'kf/vmf_a.xsd'\n",
    "tree = ET.parse(xsd_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Namespace für XSD\n",
    "ns = {'xs': 'http://www.w3.org/2001/XMLSchema'}\n",
    "\n",
    "# Dictionary zur Speicherung der ersetzten Werte\n",
    "replacement_dict = {}\n",
    "\n",
    "# Value-Werte mit Leerzeichen extrahieren und speichern\n",
    "for enumeration in root.findall(\".//xs:enumeration\", ns):\n",
    "    value = enumeration.attrib.get('value', '')\n",
    "    if ' ' in value:  # Werte mit Leerzeichen\n",
    "        split_value = value.split(' ', 1)  # Split bei erstem Leerzeichen\n",
    "        key = split_value[0]\n",
    "        full_value = value\n",
    "        replacement_dict[key] = full_value\n",
    "\n",
    "# Gruppieren nach labelx und zählen, wie viele einzigartige labelx-Werte mit jedem labela verbunden sind\n",
    "for labelx, group in unique_df.groupby('labelx'):\n",
    "    labelas = group['labela'].unique()\n",
    "    \n",
    "    if len(labelas) == 1:\n",
    "        labela = labelas[0]\n",
    "        if labela in self_loops:\n",
    "            self_loops[labela]['weight'] += 1\n",
    "            self_loops[labela]['labelx_values'].append(labelx)\n",
    "        else:\n",
    "            self_loops[labela] = {'weight': 1, 'labelx_values': [labelx]}\n",
    "        node_frequency[labela].add(labelx)\n",
    "    else:\n",
    "        for pair in combinations(labelas, 2):\n",
    "            sorted_pair = tuple(sorted(pair))\n",
    "            if sorted_pair in edges:\n",
    "                edges[sorted_pair]['weight'] += 1\n",
    "                edges[sorted_pair]['labelx_values'].append(labelx)\n",
    "            else:\n",
    "                edges[sorted_pair] = {'weight': 1, 'labelx_values': [labelx]}\n",
    "            node_frequency[pair[0]].add(labelx)\n",
    "            node_frequency[pair[1]].add(labelx)\n",
    "\n",
    "# Berechne die Häufigkeit basierend auf der Anzahl der einzigartigen labelx-Werte\n",
    "node_frequency = {node: len(labelx_set) for node, labelx_set in node_frequency.items()}\n",
    "\n",
    "# Funktion zur Skalierung der Knotengröße\n",
    "def get_node_size(frequency, min_size=10, max_size=50):\n",
    "    max_frequency = max(node_frequency.values()) if node_frequency else 1\n",
    "    return min_size + (max_size - min_size) * (frequency / max_frequency)\n",
    "\n",
    "# Schritt 3: Knoten und Kanten hinzufügen\n",
    "for (labela1, labela2), data in edges.items():\n",
    "    if data['weight'] >= min_frequency:\n",
    "        if node_frequency[labela1] >= min_unique_labelx and node_frequency[labela2] >= min_unique_labelx:\n",
    "            # Ersetzung im Titel, falls im replacement_dict vorhanden\n",
    "            title1 = replacement_dict.get(labela1, labela1)\n",
    "            title2 = replacement_dict.get(labela2, labela2)\n",
    "            \n",
    "            size1 = get_node_size(node_frequency[labela1])\n",
    "            size2 = get_node_size(node_frequency[labela2])\n",
    "            \n",
    "            net.add_node(labela1, labela1, title=f'{title1} ({node_frequency[labela1]})', size=size1)\n",
    "            net.add_node(labela2, labela2, title=f'{title2} ({node_frequency[labela2]})', size=size2)\n",
    "            \n",
    "            # Gewicht der Kante aus dem Dictionary `edges`\n",
    "            net.add_edge(labela1, labela2, value=data['weight'], title=f'{data[\"weight\"]}')\n",
    "\n",
    "# Selbstverbindungen hinzufügen\n",
    "for labela, data in self_loops.items():\n",
    "    if node_frequency[labela] >= min_unique_labelx:\n",
    "        title = replacement_dict.get(labela, labela)\n",
    "        size = get_node_size(node_frequency[labela])\n",
    "        net.add_node(labela, labela, title=f'{title} ({node_frequency[labela]})', size=size)\n",
    "        \n",
    "        # Gewicht der Selbstverbindung\n",
    "        net.add_edge(labela, labela, value=data['weight'], title=f'{data[\"weight\"]}')\n",
    "\n",
    "# Graph anzeigen\n",
    "net.show('ava.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd64325c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
