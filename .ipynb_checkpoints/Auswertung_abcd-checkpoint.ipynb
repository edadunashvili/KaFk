{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Auswertung - abcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "\n",
    "Der Code visualisiert die Verkettung von 4-Tupel-Elemente (a=Typnummer, b = Sinn und Zweck der Handlung, c = die Handlung, d = die handlungstragende Figur bzw. Figuren).\n",
    "\n",
    "Anpassbare Zeilen:\n",
    "\n",
    "(#1) Die Index des in Betracht bezogenen Typs kann durch die Variable 'mZahl' angepasst werden.\n",
    "\n",
    "(#2) Durch die Variable 'mWert' wird ein Motiv als Anhaltpunkt in der visualisierten Motivkette bestimmt. Dieser Wert wird aus der generierten Liste (#149) entnommen, nachdem als die Variable 'mZahl' (#1) bestimmt und der Code ausgeführt ist.\n",
    "\n",
    "(#3) Die Variable 'häufigkeit' bestimmt die Häufigkeit des Auftretens der Verbindung zwischen den Motiven.\n",
    "\n",
    "(#6) Pfad zu der Inputdatei.\n",
    "\n",
    "(#9) Der Attributwert bestimmt die Herkunft der zu analysierenden Textgruppe (des Repertoires). Die Filter können mit den 'or' und 'and' Operatoren ergänzt werden, z. B.:  \n",
    "\n",
    "if ('deu' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "\n",
    "    or 'ita' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:21.683424Z",
     "start_time": "2024-01-25T21:11:21.667056Z"
    }
   },
   "outputs": [],
   "source": [
    "mZahl = \"a706\"  #1 Typnummer eingeben\n",
    "\n",
    "mWert = \"a706:h:Tod_von_Angehörigen\"  #2 Ein konkretes Markupelement eingeben\n",
    "\n",
    "haeufigkeit = 3 #3 Eine ganze Zahl eingeben = Häufigkeit eines Markupelements in den ausgewerteten Daten3\n",
    "\n",
    "\n",
    "def graph_update():\n",
    "    graph.update(alle_aeste(\"\", df))\n",
    "    graph.update(alle_aeste(\"\", df))\n",
    "    graph.update(alle_aeste(\"\", df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:22.943093Z",
     "start_time": "2024-01-25T21:11:21.693040Z"
    }
   },
   "outputs": [],
   "source": [
    "maerchen = \"\"  #25 Eine leere Zeichenkette, in der Daten für Märchen gesammelt werden.\n",
    "import xml.etree.ElementTree as ET  #26 Importieren der ElementTree-Bibliothek zum Parsen von XML.\n",
    "root_node = ET.parse('gesamt_märchen.xml').getroot()  #27 Parsen der XML-Datei und Zugriff auf das Wurzelelement.\n",
    "never_saved = True  #28 Ein boolean-Wert, der angibt, ob Daten bereits gespeichert wurden oder nicht.\n",
    "#29 Iteration durch jedes 'text'-Element in der XML-Datei.\n",
    "for corp in root_node.findall (\".//{http://www.tei-c.org/ns/1.0}teiCorpus\"):\n",
    "    if \"xtk\" in corp.attrib[\"n\"]:\n",
    "        for ganze in corp.findall(\".//{http://www.tei-c.org/ns/1.0}text\"):\n",
    "            #30 Überprüfung, ob das Attribut 'deu' in der 'id'-Eigenschaft des 'text'-Elements vorhanden ist.\n",
    "            if ('zyx_' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']):\n",
    "                #31 Iteration durch jeden Absatz im 'body' des 'text'-Elements.\n",
    "                for body in ganze.findall(\".//{http://www.tei-c.org/ns/1.0}body\"):\n",
    "                    for absatz in body.findall(\".//{http://www.tei-c.org/ns/1.0}p\"):\n",
    "                        #32 Iteration durch jede 'seg'-Phrase im Absatz.\n",
    "                        for phrase in absatz.findall(\".//{http://www.tei-c.org/ns/1.0}seg\"):\n",
    "                            #33 Extrahieren von Labels und Inhalten aus den Attributen und dem Text der Phrase.\n",
    "                            labela = phrase.attrib['{www.dglab.uni-jena.de/vmf/a}ana']\n",
    "                            labelb1 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b1}ana']\n",
    "                            labelb2 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b2}ana']\n",
    "                            labelb3 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b3}ana']\n",
    "                            labelb4 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b4}ana']\n",
    "                            labelb5 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b5}ana']\n",
    "                            labelc1 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c1}ana']\n",
    "                            labelc2 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c2}ana']\n",
    "                            labelc3 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c3}ana']\n",
    "                            labelc4 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c4}ana']\n",
    "                            labelc5 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c5}ana']\n",
    "                            labeld = phrase.attrib['{www.dglab.uni-jena.de/vmf/d}ana']\n",
    "                            #34 Die Quelle wird aus dem Attribut 'id' der 'ganze'-Schleife extrahiert.\n",
    "                            quelle = ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "                            #35 Der Inhalt wird in Kleinbuchstaben umgewandelt und formatiert.\n",
    "                            inhalt = (phrase.text.lower().strip().replace('|','').replace(':','').replace(\"ä\",\"ae\")\n",
    "                                      .replace(\"ü\",\"ue\").replace(\"ö\",\"oe\").replace(\"ß\",\"ss\").replace(\",\",\"\")\n",
    "                                      .replace(\"«\",\"\").replace(\"»\",\"\").replace(\".\",\"\").replace('=',' ').replace(\";\",\"\")\n",
    "                                      .replace('\"',\"\").replace(\"?\",\"\").replace(\"!\",\"\").replace(\"á\",\"a\").replace(\",\",\"\")\n",
    "                                      .replace(\"\\t\",\" \").replace(\"'\",\"\").replace(\"‹\",\"\").replace(\"›\",\"\").replace(\"-\",\" \")\n",
    "                                      .replace(\"'('\",\"\").replace(\"')'\",\"\").replace('>','').replace(\"    \",\" \")\n",
    "                                      .replace(\"   \",\" \").replace(\"  \",\" \").replace('–','').replace('—','').replace('<','')\n",
    "                                      .replace(\"Â\", \"A\").replace(\"ø\", \"oe\").replace('“','').replace('„','').replace('(','')\n",
    "                                      .replace(')','').replace('*','').replace(\"\\n\",\"\\n\")\n",
    "                                      .replace(\"'''\",\"\"))\n",
    "                            #36 Überprüfung, ob labela mit 'a' beginnt und nicht gleich 'N' ist.\n",
    "                            if labela.startswith('a') and labelc1 != 'N':\n",
    "                                    #37 Konstruktion des Datensatzes für das Märchen und Anhängen an die 'maerchen'-Zeichenkette.\n",
    "                                    maerchen += (quelle+','+labela+','+labelb1+','+labelc1+','+labelb2+','+labelc2+','+\n",
    "                                                 labelb3+','+labelc3+','+labelb4+','+labelc4+','+labelb5+','+labelc5+','+\n",
    "                                                 labeld+','+inhalt+',0'+'\\n')                       \n",
    "with open(\"text.csv\", 'w', encoding='utf-8') as f:\n",
    "     #38 Schreiben der Kopfzeile in die CSV-Datei.\n",
    "    f.write('quelle,labela,labelb1,labelc1,labelb2,labelc2,labelb3,labelc3,labelb4,labelc4,labelb5,labelc5,labeld,inhalt,index_binar')\n",
    "    f.write('\\n')\n",
    "    #39 Schreiben der gesammelten Daten in die CSV-Datei.\n",
    "    f.write(maerchen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19 leere Zeichenketten, in der Daten für abcd1-5 gesammelt werden.\n",
    "abcd1 = \"\"\n",
    "abcd2 = \"\"\n",
    "abcd3 = \"\"\n",
    "abcd4 = \"\"\n",
    "abcd5 = \"\"\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "#20 Einlesen der CSV-Datei in ein DataFrame.\n",
    "df = pd.read_csv('text.csv', encoding='utf-8')\n",
    "\n",
    "#21 Hinzufügen von Daten an abcd1, abcd2, abcd3, abcd4 und abcd5.\n",
    "abcd1 += df.quelle+','+df.labela+':'+df.labelb1+':'+df.labelc1+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd2 += df.quelle+','+df.labela+':'+df.labelb2+':'+df.labelc2+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd3 += df.quelle+','+df.labela+':'+df.labelb3+':'+df.labelc3+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd4 += df.quelle+','+df.labela+':'+df.labelb4+':'+df.labelc4+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd5 += df.quelle+','+df.labela+':'+df.labelb5+':'+df.labelc5+':'+df.labeld+','+df.inhalt+',0'\n",
    "\n",
    "#22 Zusammenstellen der Daten aus abcd1 bis abcd5\n",
    "recorded = (abcd1 + '\\n' + abcd2 + '\\n' + abcd3 + '\\n' + abcd4 + '\\n' + abcd5 + '\\n')\n",
    "\n",
    "#23 Schreiben der aufgezeichneten Daten in eine CSV-Datei\n",
    "with open(\"text_aw.csv\", 'w', encoding='utf-8') as w:\n",
    "    w.write('quelle,index_string,inhalt,index_binar\\n')\n",
    "    w.write('000:ballast,ballast,ballast,0\\n')  #24 Schreiben einer Platzhalterzeile\n",
    "    w.write(\"\".join(recorded))  #25 Schreiben der aufgezeichneten Daten\n",
    "    \n",
    "\n",
    "mom = []  #26 Eine leere Liste zum Speichern der Daten\n",
    "\n",
    "#27 Lesen der CSV-Datei und Filtern von Zeilen mit ':N:' in der zweiten Spalte\n",
    "with open('text_aw.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        if ':N:' not in line[1]:  #28 Wenn ':N:' nicht in der zweiten Spalte enthalten ist\n",
    "            mom.append(line)  #29 Die Zeile der Liste mom hinzufügen\n",
    "            \n",
    "#30 Schreiben der gefilterten Daten in eine Textdatei.\n",
    "with open('text_ax.txt', 'wt', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(mom)  #26 Schreiben der Liste in die Datei\n",
    "    \n",
    "#31 Lesen der Textdatei und Formatieren der Daten\n",
    "with open('text_ax.txt', 'r', encoding='utf-8') as file:\n",
    "    filedata = file.read()\n",
    "filedata = (filedata.replace(']\",\"[', \"\\n\").replace('\"[', '').replace(']\"', '').replace(\" '\", \"\")\n",
    "            .replace(\"'\", \"\"))\n",
    "\n",
    "#32 Schreiben der formatierten Daten in eine CSV-Datei\n",
    "with open('text_ay.csv', 'w', encoding='utf-8') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Datei text_ay.csv wurde erfolgreich bearbeitet und gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "# Pfad zur CSV-Datei\n",
    "csv_datei = 'text_ay.csv'\n",
    "\n",
    "# Datenstruktur zum Speichern der Häufigkeit der Kombinationen\n",
    "kombinationen = defaultdict(int)\n",
    "\n",
    "# Die CSV-Datei lesen und die Häufigkeit der Kombinationen zählen\n",
    "with open(csv_datei, mode='r', newline='', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    rows = list(reader)\n",
    "\n",
    "    # Zählen der Häufigkeit jeder Kombination\n",
    "    for row in rows:\n",
    "        kombination = (row['quelle'], row['index_string'])\n",
    "        kombinationen[kombination] += 1\n",
    "\n",
    "# Die Kombinationen-Häufigkeiten zurücksetzen, um die Bearbeitung durchzuführen\n",
    "kombinationen = defaultdict(int)\n",
    "\n",
    "# Die CSV-Datei bearbeiten, wobei wiederholte Kombinationen entsprechend der Häufigkeit 'x' erhalten\n",
    "for row in rows:\n",
    "    kombination = (row['quelle'], row['index_string'])\n",
    "    kombinationen[kombination] += 1\n",
    "    if kombinationen[kombination] > 1:\n",
    "        # Hängt entsprechend der Wiederholung so viele '_x' an\n",
    "        row['index_string'] += '_x' * (kombinationen[kombination] - 1) #alternativ gilt für mehrmalige '_x' \n",
    "        #row['index_string'] += '_x' #alternativ gilt für einmalige '_x' \n",
    "\n",
    "# Die bearbeitete CSV-Datei unter demselben Namen speichern\n",
    "with open(csv_datei, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=rows[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Die Datei {csv_datei} wurde erfolgreich bearbeitet und gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:24.190477Z",
     "start_time": "2024-01-25T21:11:24.156617Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "\n",
    "df = pd.read_csv('text_ay.csv', encoding='utf-8')  #33 Einlesen der Daten aus einer CSV-Datei in ein DataFrame\n",
    "\n",
    "#34 Eine Funktion zur Formatierung der Markupelemente eines Märchens\n",
    "def ep_format(ep_full):\n",
    "    return (ep_full.split(':'))[0]\n",
    "\n",
    "#35 Eine Funktion zur Formatierung des Typs eines Märchens.\n",
    "def ep_name_format(ep_full):\n",
    "    sublist = (ep_full)\n",
    "    name = \"\"\n",
    "    for strg in sublist:\n",
    "        name += strg\n",
    "    return name\n",
    "\n",
    "#36 Eine Funktion zum Vergleich von Quellen in einem DataFrame.\n",
    "def quellenvergleich(df, i1, i2):\n",
    "    return df.quelle[i1] == df.quelle[i2]\n",
    "\n",
    "#37 Eine Funktion zur Analyse von Abschnitten eines Märchens.\n",
    "def ast(gesep, df):\n",
    "    ep_tree = {}  #38 Ein leeres Dictionary zur Speicherung der Analyseergebnisse.\n",
    "    a_liste = []  #39 Eine leere Liste zur Speicherung von Startabschnitten.\n",
    "    z_liste = []  #40 Eine leere Liste zur Speicherung von Endabschnitten.\n",
    "    df_len = len(df.index_string)  #36 Die Anzahl der Zeilen im DataFrame.\n",
    "    for i, ep in enumerate(df.index_string):  #41 Iteration durch die 'Index-String' des DataFrames.\n",
    "        if gesep == ep:  #42 Wenn der aktuelle Abschnitt dem gesuchten Abschnitt entspricht.\n",
    "            if (i > 0) and (quellenvergleich(df, i, i - 1)):  #43 Wenn es einen vorherigen Abschnitt gibt und die Quellen übereinstimmen.\n",
    "                a = df.index_string[i - 1]  #44 Der vorherige Abschnitt wird als Startabschnitt betrachtet.\n",
    "            else:\n",
    "                a = 'Anf-' + ep_name_format(gesep)  #45 Ansonsten wird ein neuer Startabschnitt erstellt.\n",
    "            if (i < df_len - 1):  #46 Wenn es einen nächsten Abschnitt gibt.\n",
    "                if not (quellenvergleich(df, i, i + 1)):  #47 Wenn die Quellen des nächsten Abschnitts unterschiedlich sind.\n",
    "                    z = 'End-' + ep_name_format(gesep)  #48 Der aktuelle Abschnitt wird als Endabschnitt betrachtet.\n",
    "                else:\n",
    "                    z = df.index_string[i + 1]  #49 Ansonsten wird der nächste Abschnitt als Endabschnitt betrachtet.\n",
    "            else:\n",
    "                z = 'End-' + ep_name_format(gesep)  #50 Wenn es keinen nächsten Abschnitt gibt, wird ein neuer Endabschnitt erstellt.\n",
    "            a_liste.append(a)  #51 Startabschnitt wird der Liste hinzugefügt.\n",
    "            z_liste.append(z)  #52 Endabschnitt wird der Liste hinzugefügt.\n",
    "    return {gesep: [Counter(a_liste), Counter(z_liste)]}  #53 Rückgabe der Analyseergebnisse als Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:25.557996Z",
     "start_time": "2024-01-25T21:11:25.546033Z"
    }
   },
   "outputs": [],
   "source": [
    "def alle_aeste(gesep, df):\n",
    "    episoden_baeume = {}  #54 Ein leeres Dictionary zur Speicherung der Analyseergebnisse.\n",
    "    ep_list = []  #55 Eine leere Liste zur Speicherung von Episoden.\n",
    "    for ep_full in df.index_string:  #56 Iteration durch die 'Index-String' des DataFrames.\n",
    "        ep = ep_format(ep_full)  #57 Formatierung der Episode.\n",
    "        if gesep == ep:  #58 Wenn die gesuchte Episode gefunden wird.\n",
    "            ep_list.append(ep_full)  #59 Die Episode wird zur Liste hinzugefügt.\n",
    "    for ep in set(ep_list):  #60 Iteration durch jede einzigartige Episode in der Liste.\n",
    "        episoden_baeume.update(ast(ep, df))  #61 Die Analyseergebnisse für jede Episode werden dem Dictionary hinzugefügt.\n",
    "    return episoden_baeume  #62 Rückgabe des Dictionary mit den Analyseergebnissen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def key_val_printer(d):\n",
    "#     for k, v in d.items():\n",
    "#         print(v, k, sep=':')\n",
    "# def baum_printer(baeume: dict, baum: str):\n",
    "#     key_val_printer(baeume[baum][0])\n",
    "#     print(65*'-')\n",
    "#     print(sum(baeume[baum][0].values()),':', baum)\n",
    "#     print(65*'-')\n",
    "#     key_val_printer(baeume[baum][1]) \n",
    "# def wald_printer(wald: dict):\n",
    "#     for baum in (wald.keys()): # for baum in sorted(wald.keys():\n",
    "#         baum_printer (wald, baum)\n",
    "#         print(65*'=')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:29.915657Z",
     "start_time": "2024-01-25T21:11:29.903072Z"
    }
   },
   "outputs": [],
   "source": [
    "#63 Die Variable 'graph' wird mit den Analyseergebnissen für die Episode 'mZahl' initialisiert.\n",
    "graph = alle_aeste(mZahl, df)\n",
    "graph_update()\n",
    "#wald_printer(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:31.249124Z",
     "start_time": "2024-01-25T21:11:30.925952Z"
    }
   },
   "outputs": [],
   "source": [
    "## import matplotlib.pyplot as plt  #64 Importieren der matplotlib.pyplot-Bibliothek zur Visualisierung von Daten.\n",
    "import networkx as nx  #65 Importieren der networkx-Bibliothek zur Erstellung und Analyse von Netzwerken.\n",
    "#66 Eine Funktion zum Filtern von Daten für einen bestimmten Ast.\n",
    "def cutoff_ast_data(wuerzel, graph, nachbar_liste, cutoff=0):\n",
    "    vor = graph[wuerzel][0]  #67 Vorwärtsverbindungen des Astes.\n",
    "    zurueck = graph[wuerzel][1]  #68 Rückwärtsverbindungen des Astes.\n",
    "    nachbarn = vor.copy()  #69 Kopie der Vorwärtsverbindungen.\n",
    "    nachbarn.update(zurueck)  #70 Hinzufügen der Rückwärtsverbindungen.\n",
    "    for ast_name, ast_gewicht in sorted(nachbarn.items()):  #71 Iteration durch die Nachbarn des Astes.\n",
    "        if (ast_gewicht >= cutoff):  #72 Wenn das Gewicht größer oder gleich dem Cutoff-Wert ist.\n",
    "            nachbar_liste.append([ep_name_format(wuerzel),\n",
    "                                   ep_name_format(ast_name), ast_gewicht])  #73 Die Verbindung wird der Nachbarliste hinzugefügt.\n",
    "#74 Eine Funktion zum Filtern von Daten für den gesamten Graphen.\n",
    "def cutoff_graph_data(graph, cutoff=0):\n",
    "    nachbar_liste = []  #75 Eine leere Liste zur Speicherung der Nachbarn.\n",
    "    for i, (k, v) in enumerate(sorted(graph.items())):  #76 Iteration durch die Elemente des Graphen.\n",
    "        cutoff_ast_data(k, graph, nachbar_liste, cutoff)  #77 Filtern der Daten für jeden Ast.\n",
    "    neue_nachbar_liste = [[i, nachbar] for i, nachbar in enumerate(nachbar_liste)]  #78 Indexierung der Nachbarn.\n",
    "    return neue_nachbar_liste  #79 Rückgabe der gefilterten Nachbardaten.\n",
    "#80 Eine Funktion zur Aktualisierung der interaktiven Daten des Graphen.\n",
    "def interactive_graph_data(graph_data, loesch_index, gew_dict):\n",
    "    for k, v in gew_dict.items():  #81 Iteration durch die Gewichts-Daten.\n",
    "        graph_data[k][1][2] = v  #82 Aktualisieren der Gewichts-Daten.\n",
    "    neue_nachbar_liste = [[i, nachbar[1]] for i,\n",
    "                          nachbar in enumerate(graph_data) if i not in loesch_index]  #83 Filtern der Daten.\n",
    "    return neue_nachbar_liste  #84 Rückgabe der aktualisierten Daten.\n",
    "import networkx as nx\n",
    "\n",
    "def graph_bauer(graph_data):\n",
    "    G = nx.DiGraph()  #86 Initialisierung eines gerichteten Graphen.\n",
    "    w_liste = []  #87 Eine leere Liste zur Speicherung der Gewichts-Daten.\n",
    "    for el in graph_data:  #88 Iteration durch die Elemente der Graphendaten.\n",
    "        n1 = el[1][0]  #89 Der Ausgangsknoten der Verbindung.\n",
    "        n2 = el[1][1]  #90 Der Zielknoten der Verbindung.\n",
    "        w = el[1][2]  #91 Das Gewicht der Verbindung.\n",
    "        w_liste.append(w)  #92 Hinzufügen des Gewichts zur Liste.\n",
    "        #93 Hinzufügen der Verbindung und der Knoten zum Graphen.\n",
    "        wght = int(w*1)\n",
    "        G.add_edge (n1, n2, weight=wght, title=w, Value = w)\n",
    "        #G.add_edge (n1, n2, weight=w, title=w, Value=2)\n",
    "        G.add_node(n1, title=n1, size=30)\n",
    "        G.add_node(n2, title=n2, size=30)\n",
    "        \n",
    "        \n",
    "    return G, w_liste  #94 Rückgabe des Graphen und der Gewichtsliste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:32.130557Z",
     "start_time": "2024-01-25T21:11:32.122432Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#95 Filtern der Graphendaten basierend auf der Häufigkeit.\n",
    "auto_graph = cutoff_graph_data(graph, haeufigkeit)\n",
    "G, W = graph_bauer(auto_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:12:53.897428Z",
     "start_time": "2024-01-25T21:12:53.677815Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network \n",
    "#96 Erstellen des Graphen und der Gewichtsliste aus den Graphendaten.\n",
    "G, W = graph_bauer(auto_graph)\n",
    "\n",
    "#97 Erstellen einer Network-Instanz für die Visualisierung des Graphen.\n",
    "nt = Network(notebook=True,  #98 Das Netzwerk wird im Jupyter Notebook angezeigt.\n",
    "             height='1300px',  #99 Höhe des Netzwerks.default=650\n",
    "             width='1800px',  #100 Breite des Netzwerks.default=1300\n",
    "             directed=False,  #101 Der Graph ist ungerichtet.\n",
    "             neighborhood_highlight=True,\n",
    "             bgcolor='#ffffff',  #102 Hintergrundfarbe des Netzwerks.\n",
    "             font_color='black',  #103 Die Farbe der Schrift im Netzwerk wird automatisch festgelegt.\n",
    "             layout=None,  #104 Die Layout-Eigenschaft wird nicht gesetzt (standardmäßig wird ein Fruchterman-Reingold-Layout verwendet).\n",
    "             heading='',  #105 Ein leerer Titel für das Netzwerk.\n",
    "             filter_menu=True,\n",
    "             select_menu=True,\n",
    "             cdn_resources='in_line')  #106 Die Ressourcen werden lokal geladen (ohne Internetverbindung).\n",
    "#107 Fügen Sie die Knoten und Kanten des Graphen zur Netzwerkinstanz hinzu.\n",
    "nt.from_nx(G)\n",
    "\n",
    "#108 Anzeigen des Netzwerks im Jupyter Notebook.\n",
    "with open('nx_2.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(nt.generate_html())  # Erzeugt HTML mit UTF-8 Unterstützung\n",
    "#nt.show('nx.html')  #109 Die Visualisierung wird in einer HTML-Datei gespeichert und im Notebook angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T20:53:45.643261Z",
     "start_time": "2024-01-25T20:53:45.629312Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv  \n",
    "import numpy as np \n",
    "#110 Eine Funktion zur Überprüfung, ob ein Nachbar in einen Knoten einbezogen werden kann.\n",
    "def neighbour_is_includable(node, neighbour):\n",
    "    designation = \":\".join(node.split(\":\")[0:1])  #111 Extrahieren der Bezeichnung des Knotens.\n",
    "    return neighbour.startswith(designation)  #112 Rückgabe, ob der Nachbar in den Knoten einbezogen werden kann.\n",
    "#113 Eine Funktion zur Bereinigung der Kanten basierend auf der Einbeziehbarkeit.\n",
    "def pruned_edges(node, neighbours):\n",
    "    return [neighbor for neighbor in neighbours if neighbour_is_includable(node, neighbor)]\n",
    "#114 Eine Funktion zur Erstellung eines bereinigten Graphen.\n",
    "def make_pruned_graph(graph):\n",
    "    pruned_graph = {}\n",
    "    for node, (incoming, outgoing) in graph.items():\n",
    "        pruned_incoming = pruned_edges(node, incoming)\n",
    "        pruned_outgoing = pruned_edges(node, outgoing)\n",
    "        pruned_graph[node] = (pruned_incoming, pruned_outgoing)\n",
    "    return pruned_graph\n",
    "#115 Eine Funktion zur Erstellung eines gerichteten Rückgrat-Graphen.\n",
    "def make_backbone_di_graph(pruned_graph):\n",
    "    new_DiGraph = nx.DiGraph()\n",
    "    for node, (incoming, outgoing) in pruned_graph.items():\n",
    "        for in_node in incoming:\n",
    "            new_DiGraph.add_edge(in_node, node)\n",
    "        for out_node in outgoing:\n",
    "            new_DiGraph.add_edge(node, out_node)\n",
    "    return new_DiGraph\n",
    "#116 Eine Funktion zur Berechnung der kürzesten Pfade mit Vorzeichen.\n",
    "def signed_shortest_path_length(G, source, target):\n",
    "    try:\n",
    "        pl = nx.dijkstra_path_length(G, source=source, target=target)\n",
    "    except nx.NodeNotFound:\n",
    "        pl = np.Inf\n",
    "    except nx.NetworkXNoPath:\n",
    "        try:\n",
    "            pl = - nx.dijkstra_path_length(G, source=target, target=source)\n",
    "        except nx.NodeNotFound:\n",
    "            pl = np.Inf\n",
    "        except nx.NetworkXNoPath:\n",
    "            pl = np.Inf\n",
    "    return pl\n",
    "\n",
    "#     try:\n",
    "#         pl = nx.dijkstra_path_length(G, source=source, target=target)\n",
    "#     except nx.NetworkXNoPath:\n",
    "#         try:\n",
    "#             pl = - nx.dijkstra_path_length(G, source=target, target=source)\n",
    "#         except nx.NetworkXNoPath:\n",
    "#             pl = np.Inf\n",
    "#     return pl\n",
    "\n",
    "\n",
    "#117 Eine Funktion zur Erstellung von Distanzdaten für Hauptknoten.\n",
    "def create_main_node_distances(start_node, pruned_graph, graph, nx_graph):\n",
    "    distances = { key:[] for key in graph}\n",
    "    backbone_di_graph= make_backbone_di_graph(pruned_graph)\n",
    "    for node in pruned_graph:\n",
    "        distances[node] = {signed_shortest_path_length(backbone_di_graph, start_node, node)}\n",
    "    return distances\n",
    "#118 Eine Funktion zum Hinzufügen von Distanzdaten für Unter- bzw. Nebenknoten.\n",
    "def add_sub_node_distances(node, sub_nodes, pruned_graph, distances, d):\n",
    "    for sub_node in sub_nodes:\n",
    "        if sub_node not in pruned_graph.keys():\n",
    "            if sub_node not in distances:\n",
    "                distances[sub_node] = set()\n",
    "            new_dists = {dist + d for dist in distances[node]}\n",
    "            distances[sub_node].update(new_dists)\n",
    "#119 Eine Funktion zur Erstellung eines Distanz-Dictionarys.\n",
    "def create_distance_dict(start_node, graph, G):\n",
    "    pruned_graph = make_pruned_graph(graph)\n",
    "    distances = create_main_node_distances(start_node, pruned_graph, graph, G)\n",
    "    for node, (incoming, outgoing) in graph.items():\n",
    "        add_sub_node_distances(node, incoming, pruned_graph, distances, -1)\n",
    "        add_sub_node_distances(node, outgoing, pruned_graph, distances, 1)\n",
    "    return distances\n",
    "#120 Startknoten für die Berechnung der Distanzen.\n",
    "start_node = mWert\n",
    "#121 Erstellen der Distanzdaten.\n",
    "distances = create_distance_dict(start_node, graph, G)\n",
    "#122 Sortieren der Distanzdaten nach den minimalen Distanzen.\n",
    "sorted_keys = sorted(distances, key=lambda x: min(distances[x]))\n",
    "sorted_distances = {key: distances[key] for key in sorted_keys}\n",
    "#123 Konvertierung der Distanzdaten in eine Zeichenfolge für den HTML-Output.\n",
    "msia=\"\"\n",
    "tai = []\n",
    "for k, v in sorted_distances.items():\n",
    "    sia=(f\"{k} {v}\")\n",
    "    msia+=sia+'<br>'\n",
    "    tai.append(sia)\n",
    "    #print(sia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#124 Pfad zur CSV-Datei\n",
    "csv_file_path = 'output_1.csv'\n",
    "#125 Schreibe die Daten in die CSV-Datei\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')  \n",
    "    #126 Schreibe die Überschrift (Header) in die CSV-Datei\n",
    "    writer.writerow([''])\n",
    "    #127 Schreibe die Zeilen in die CSV-Datei\n",
    "    for data in tai:\n",
    "        writer.writerow([data])\n",
    "        #print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#128 Diese Funktion erstellt eine Menge aus den ausgewählten Knoten basierend auf den Kanten im Graphen.\n",
    "def make_set_of_chosen_vertices(graph_edge_data):\n",
    "    chosen_vertices = set()  #129 Initialisierung einer leeren Menge für ausgewählte Knoten\n",
    "    for sub_list in graph_edge_data:  #130 Iteration durch die Kanten im Graphen\n",
    "        sub_sub_list = sub_list[1]  #131 Die Kanteninformationen befinden sich in der zweiten Unterliste\n",
    "        chosen_vertices.add(sub_sub_list[0])  #132 Hinzufügen des ersten Knotens der Kante zur Menge ausgewählter Knoten\n",
    "        chosen_vertices.add(sub_sub_list[1])  #133 Hinzufügen des zweiten Knotens der Kante zur Menge ausgewählter Knoten\n",
    "    return chosen_vertices  #134 Rückgabe der Menge ausgewählter Knoten\n",
    "\n",
    "dat = []  #135 Initialisierung einer leeren Liste 'dat' für Daten\n",
    "\n",
    "#136 'graph_data' enthält die Informationen über die Kanten im Graphen, basierend auf einer bestimmten Häufigkeitsschwelle ('haeufigkeit')\n",
    "graph_data = cutoff_graph_data(graph, haeufigkeit)\n",
    "\n",
    "#137 Die ausgewählten Knoten werden aus der Menge ausgewählt und sortiert\n",
    "chosen_vertices = list(make_set_of_chosen_vertices(graph_data))  \n",
    "#chosen_vertices.sort()  \n",
    "\n",
    "#138 Iteration durch die ausgewählten Knoten\n",
    "for vertex_name in chosen_vertices:\n",
    "    dat.append(vertex_name)  #134 Hinzufügen des Knotennamens zur Liste 'dat'\n",
    "csv_file_path = 'output_2.csv'\n",
    "#139 Schreibe die Daten in die CSV-Datei\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')    \n",
    "    #140 Schreibe die Überschrift (Header) in die CSV-Datei\n",
    "    writer.writerow([''])\n",
    "    #141 Schreibe die Zeilen in die CSV-Datei\n",
    "    for data in dat:\n",
    "        writer.writerow([data])\n",
    "        #print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ = a706\n",
      "Referenz-Motiv = a706:h:Tod_von_Angehörigen\n",
      "Häufigkeit = 3\n",
      "\n",
      "a706:H:Familienzusammenführung:rHD_rPP {inf}\n",
      "a706:h:SCHLAF:rVB_fHH_x {inf}\n",
      "a706:H:VERLEUMDUNG_beheben:rHD_rHH_fHH_x {inf}\n",
      "a706:H:BOTSCHAFTEN_versenden:rVB_rHP {inf}\n",
      "a706:h:BOTSCHAFTEN_verfälschen:rVB_fHH_x {inf}\n",
      "a706:h:BOTSCHAFTEN_verfälschen:rVB_fHH {inf}\n",
      "a706:h:VERTREIBUNG:rHD_rHP {inf}\n",
      "a706:h:VERTREIBUNG:rHD_rHH {inf}\n",
      "a706:H:VERLEUMDUNG_beheben:rHD_rHH_fHH {inf}\n",
      "a706:h:VERLEUMDUNG_bei_Kindstötung:rHD_rHH_fHH {inf}\n",
      "a706:F:Liebe_wird_ausgelöst:rHD_rPP {inf}\n",
      "a706:H:BOTSCHAFTEN_versenden:rVB_rPP {inf}\n",
      "a706:h:KINDERMORD_nachgehen:rHD_rHH_fHH {inf}\n",
      "a706:F:Überrascht_werden:rHD_rPP {inf}\n",
      "a706:Hh:KONTAKT_abbrechen:rHD_rPP {inf}\n",
      "a706:h:SCHLAF:rVB_fHH {inf}\n",
      "a706:h:VERLEUMDUNG_bei_Schädigung:rHD_rHH_fHH_x {inf}\n",
      "a706:H:Bestrafung_erfolgt:rHH_fHH {inf}\n",
      "a706:h:VERLEUMDUNG_bei_Schädigung:rHD_rHH_fHH {inf}\n",
      "a706:h:BEHINDERUNG_durch_Verstümmelung:rHD_rHH {inf}\n",
      "End-a706:H:Familienzusammenführung:rHD_rPP {inf}\n"
     ]
    }
   ],
   "source": [
    "#142 Liste a\n",
    "sia_a=[]\n",
    "with open('output_1.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f) \n",
    "    for line in reader:\n",
    "            sia_a.append(line)\n",
    "#143 Liste b\n",
    "sia_b=[]         \n",
    "with open('output_2.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f) \n",
    "    for line in reader:\n",
    "            sia_b.append(line)\n",
    "#144 Liste c\n",
    "sia_c=[]\n",
    "#145 Iteriere durch Liste a\n",
    "for element_a in sia_a:\n",
    "    #146 Extrahiere den linken String aus dem ersten Element in Liste a\n",
    "    left_string_a = element_a[0].split(' ')[0]\n",
    "\n",
    "    #147 Überprüfe, ob der linke String aus Liste a in Liste b vorhanden ist\n",
    "    if any(left_string_a == element_b[0] for element_b in sia_b):\n",
    "        #148 Wenn ja, füge das aktuelle Element aus Liste a zu Liste c hinzu\n",
    "        sia_c.append(element_a[0])\n",
    "#149 Ausgabe der generierten Liste c\n",
    "print(f'Typ = {mZahl}\\nReferenz-Motiv = {mWert}\\nHäufigkeit = {haeufigkeit}')\n",
    "for element_c in sia_c:\n",
    "    print(element_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nt.from_nx(G)  #150 Konvertiere den NetworkX-Graphen G in ein pyvis-Network-Objekt\n",
    "# print(f'Typ: {mZahl}\\nMotiv: {mWert}\\nHäufigkeit: {haeufigkeit}')  #148 Gib Informationen über den Graphen aus\n",
    "# nt.show('nx.html')  #149 Speichere die Visualisierung als HTML-Datei und zeige sie an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einer oder beide Knoten wurden nicht gefunden.\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "# Baue den Graphen mit der `graph_bauer`-Funktion\n",
    "G, w_liste = graph_bauer(graph_data)\n",
    "\n",
    "def highlight_path_between_nodes(G, node1, node2):\n",
    "    # Erstellen einer Network-Instanz für die Visualisierung des Graphen\n",
    "    nt = Network(height='600px', \n",
    "                 width='100%', \n",
    "                 directed=False, \n",
    "                 notebook=True, \n",
    "                 neighborhood_highlight=False, \n",
    "                 bgcolor='#ffffff',\n",
    "                 font_color='black', \n",
    "                 layout=None,\n",
    "                 cdn_resources='local')\n",
    "    \n",
    "    # Berechnung des kürzesten Pfades zwischen den beiden Knoten\n",
    "    try:\n",
    "        path = nx.shortest_path(G, source=node1, target=node2, weight='weight')\n",
    "    except nx.NetworkXNoPath:\n",
    "        path = []\n",
    "    \n",
    "    # Knoten hinzufügen und hervorheben\n",
    "    for node, data in G.nodes(data=True):\n",
    "        color = 'lightblue'\n",
    "        title = data.get('title', '')\n",
    "        if node == node1 or node == node2:\n",
    "            color = 'red'\n",
    "        nt.add_node(node, title=title, color=color)\n",
    "    \n",
    "    # Kanten hinzufügen und Pfad markieren\n",
    "    edge_seen = set()  # Set für bereits hinzugefügte Kanten\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        weight = data.get('weight', 1)\n",
    "        color = 'gray'  # Standardfarbe\n",
    "        width = 1  # Standardbreite\n",
    "        \n",
    "        # Pfad-Markierung\n",
    "        if (u, v) in zip(path, path[1:]) or (v, u) in zip(path, path[1:]):\n",
    "            color = 'red'  # Markierung des Pfades\n",
    "            width = 5\n",
    "        \n",
    "        # Hinzufügen der Kante zum Pyvis-Graphen, nur wenn sie noch nicht hinzugefügt wurde\n",
    "        if (u, v) not in edge_seen and (v, u) not in edge_seen:\n",
    "            nt.add_edge(u, v, value=weight, title=f\"{weight}\", color=color, width=width)\n",
    "            edge_seen.add((u, v))\n",
    "            edge_seen.add((v, u))\n",
    "    \n",
    "    # Visualisierung anzeigen\n",
    "    nt.show('Weg.html')\n",
    "\n",
    "# Beispiel-Suchbegriffe\n",
    "search_query_node1 = \"a551:h:KRANKHEIT:rHH\"\n",
    "search_query_node2 = \"a551:H:Heiraten:rHD_rBZ\"  # Ersetze dies durch den tatsächlichen Suchbegriff für den zweiten Knoten\n",
    "\n",
    "# Suche nach den Knoten\n",
    "def find_node(G, query):\n",
    "    for node, data in G.nodes(data=True):\n",
    "        if query.lower() in data.get('title', '').lower():\n",
    "            return node\n",
    "    return None\n",
    "\n",
    "node1 = find_node(G, search_query_node1)\n",
    "node2 = find_node(G, search_query_node2)\n",
    "\n",
    "if node1 and node2:\n",
    "    highlight_path_between_nodes(G, node1, node2)\n",
    "else:\n",
    "    print(\"Einer oder beide Knoten wurden nicht gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "# Such- und Hervorhebungsfunktion für Pyvis\n",
    "def search_and_highlight_pyvis(G, query):\n",
    "    if not isinstance(G, nx.Graph):\n",
    "        raise TypeError(\"Das übergebene Objekt ist kein NetworkX-Graph.\")\n",
    "\n",
    "    # Erstellen einer Network-Instanz für die Visualisierung des Graphen\n",
    "    nt = Network(height='600px', \n",
    "                 width='100%', \n",
    "                 directed=False,  # Graph ist gerichtet, falls der ursprüngliche Graph gerichtet ist\n",
    "                 notebook=True, \n",
    "                 bgcolor='#ffffff', \n",
    "                 neighborhood_highlight=False, \n",
    "                 font_color='black', \n",
    "                 layout=None,\n",
    "                 heading='',\n",
    "                 select_menu=True,\n",
    "                 filter_menu=True,\n",
    "                 cdn_resources='in_line')\n",
    "    \n",
    "    # Farbe der Knoten basierend auf der Suchanfrage\n",
    "    node_color = {}\n",
    "    for node, data in G.nodes(data=True):\n",
    "        if query.lower() == data.get('title', '').lower():\n",
    "            node_color[node] = 'red'  # Hervorhebung\n",
    "        else:\n",
    "            node_color[node] = None  # Standardfarbe lightblue\n",
    "    \n",
    "    # Knoten hinzufügen (mit entsprechender Farbe und Hover-Effekt für Titel)\n",
    "    for node, color in node_color.items():\n",
    "        title = G.nodes[node].get('title', '')\n",
    "        nt.add_node(node, color=color, title=title, size=25)  # Titel erscheint beim Hover\n",
    "    \n",
    "    # Kanten hinzufügen mit Gewicht und Tooltip\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        weight = data.get('weight', 1)\n",
    "        nt.add_edge(u, v, value=weight, title=f\"{weight}\", width=weight, color='gray')\n",
    "        \n",
    "    \n",
    "    # Datei mit UTF-8-Kodierung speichern\n",
    "    with open('Zielknoten.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(nt.generate_html())  # Erzeugt HTML mit UTF-8 Unterstützung\n",
    "\n",
    "# Beispiel-Suchbegriff\n",
    "search_query = mWert\n",
    "\n",
    "# Baue den Graphen mit der `graph_bauer`-Funktion\n",
    "G, w_liste = graph_bauer(graph_data)\n",
    "\n",
    "# Suche und Hervorhebung auf dem vorhandenen Graphen anwenden\n",
    "search_and_highlight_pyvis(G, search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
