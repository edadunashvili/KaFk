{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Auswertung - abc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "\n",
    "Der Code visualisiert die Verkettung von 3-Tupel-Elemente (a=Typnummer, b = Sinn und Zweck der Handlung, c = die Handlung).\n",
    "\n",
    "\n",
    "Anpassbare Zeilen:\n",
    "\n",
    "(#1) Die Index des in Betracht bezogenen Typs kann durch die Variable 'mZahl' angepasst werden.\n",
    "\n",
    "(#2) Durch die Variable 'mWert' wird ein Motiv als Anhaltpunkt in der visualisierten Motivkette bestimmt. Dieser Wert wird aus der generierten Liste (siehe #149) entnommen, nachdem als die Variable 'mZahl' (siehe #1) bestimmt und der Code ausgeführt ist.\n",
    "\n",
    "(#3) Die Variable 'häufigkeit' bestimmt die Häufigkeit des Auftretens der Verbindung zwischen den Motiven.\n",
    "\n",
    "(#6) Pfad zu der Inputdatei.\n",
    "\n",
    "(#9) Der Attributwert bestimmt die Herkunft der zu analysierenden Textgruppe (des Repertoires). Die Filter können mit den 'or' und 'and' Operatoren ergänzt werden, z. B.:  \n",
    "\n",
    "if ('deu' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "\n",
    "    or 'ita' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mZahl = \"a1920F\"  #1 Typnummer eingeben\n",
    "\n",
    "mWert = \"a1633:h:Tod_von_Angehörigen\"  #2 Ein konkretes Markupelement eingeben\n",
    "\n",
    "haeufigkeit = 1 #3 Eine ganze Zahl eingeben = Häufigkeit eines Markupelements in den ausgewerteten Daten3\n",
    "\n",
    "\n",
    "def graph_update():\n",
    "    graph.update(alle_aeste(\"a1633\", df))\n",
    "    graph.update(alle_aeste(\"a1960\", df))\n",
    "    graph.update(alle_aeste(\"\", df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "maerchen = \"\"  #25 Eine leere Zeichenkette, in der Daten für Märchen gesammelt werden.\n",
    "import xml.etree.ElementTree as ET  #26 Importieren der ElementTree-Bibliothek zum Parsen von XML.\n",
    "root_node = ET.parse('gesamt_märchen.xml').getroot()  #27 Parsen der XML-Datei und Zugriff auf das Wurzelelement.\n",
    "never_saved = True  #28 Ein boolean-Wert, der angibt, ob Daten bereits gespeichert wurden oder nicht.\n",
    "#29 Iteration durch jedes 'text'-Element in der XML-Datei.\n",
    "for corp in root_node.findall (\".//{http://www.tei-c.org/ns/1.0}teiCorpus\"):\n",
    "    if \"xtk\" in corp.attrib[\"n\"]:\n",
    "        for ganze in corp.findall(\".//{http://www.tei-c.org/ns/1.0}text\"):\n",
    "            #30 Überprüfung, ob das Attribut 'deu' in der 'id'-Eigenschaft des 'text'-Elements vorhanden ist.\n",
    "            if ('zyx_' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']):\n",
    "                #31 Iteration durch jeden Absatz im 'body' des 'text'-Elements.\n",
    "                for body in ganze.findall(\".//{http://www.tei-c.org/ns/1.0}body\"):\n",
    "                    for absatz in body.findall(\".//{http://www.tei-c.org/ns/1.0}p\"):\n",
    "                        #32 Iteration durch jede 'seg'-Phrase im Absatz.\n",
    "                        for phrase in absatz.findall(\".//{http://www.tei-c.org/ns/1.0}seg\"):\n",
    "                            #33 Extrahieren von Labels und Inhalten aus den Attributen und dem Text der Phrase.\n",
    "                            labela = phrase.attrib['{www.dglab.uni-jena.de/vmf/a}ana']\n",
    "                            labelb1 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b1}ana']\n",
    "                            labelb2 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b2}ana']\n",
    "                            labelb3 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b3}ana']\n",
    "                            labelb4 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b4}ana']\n",
    "                            labelb5 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b5}ana']\n",
    "                            labelc1 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c1}ana']\n",
    "                            labelc2 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c2}ana']\n",
    "                            labelc3 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c3}ana']\n",
    "                            labelc4 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c4}ana']\n",
    "                            labelc5 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c5}ana']\n",
    "                            labeld = phrase.attrib['{www.dglab.uni-jena.de/vmf/d}ana']\n",
    "                            #34 Die Quelle wird aus dem Attribut 'id' der 'ganze'-Schleife extrahiert.\n",
    "                            quelle = ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "                            #35 Der Inhalt wird in Kleinbuchstaben umgewandelt und formatiert.\n",
    "                            inhalt = (phrase.text.lower().strip().replace('|','').replace(':','').replace(\"ä\",\"ae\")\n",
    "                                      .replace(\"ü\",\"ue\").replace(\"ö\",\"oe\").replace(\"ß\",\"ss\").replace(\",\",\"\")\n",
    "                                      .replace(\"«\",\"\").replace(\"»\",\"\").replace(\".\",\"\").replace('=',' ').replace(\";\",\"\")\n",
    "                                      .replace('\"',\"\").replace(\"?\",\"\").replace(\"!\",\"\").replace(\"á\",\"a\").replace(\",\",\"\")\n",
    "                                      .replace(\"\\t\",\" \").replace(\"'\",\"\").replace(\"‹\",\"\").replace(\"›\",\"\").replace(\"-\",\" \")\n",
    "                                      .replace(\"'('\",\"\").replace(\"')'\",\"\").replace('>','').replace(\"    \",\" \")\n",
    "                                      .replace(\"   \",\" \").replace(\"  \",\" \").replace('–','').replace('—','').replace('<','')\n",
    "                                      .replace(\"Â\", \"A\").replace(\"ø\", \"oe\").replace('“','').replace('„','').replace('(','')\n",
    "                                      .replace(')','').replace('*','').replace(\"\\n\",\"\\n\")\n",
    "                                      .replace(\"'''\",\"\"))\n",
    "                            #36 Überprüfung, ob labela mit 'a' beginnt und nicht gleich 'N' ist.\n",
    "                            if labela.startswith('a') and labelc1 != 'N':\n",
    "                                    #37 Konstruktion des Datensatzes für das Märchen und Anhängen an die 'maerchen'-Zeichenkette.\n",
    "                                    maerchen += (quelle+','+labela+','+labelb1+','+labelc1+','+labelb2+','+labelc2+','+\n",
    "                                                 labelb3+','+labelc3+','+labelb4+','+labelc4+','+labelb5+','+labelc5+','+\n",
    "                                                 labeld+','+inhalt+',0'+'\\n')                       \n",
    "with open(\"text.csv\", 'w', encoding='utf-8') as f:\n",
    "     #38 Schreiben der Kopfzeile in die CSV-Datei.\n",
    "    f.write('quelle,labela,labelb1,labelc1,labelb2,labelc2,labelb3,labelc3,labelb4,labelc4,labelb5,labelc5,labeld,inhalt,index_binar')\n",
    "    f.write('\\n')\n",
    "    #39 Schreiben der gesammelten Daten in die CSV-Datei.\n",
    "    f.write(maerchen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 leere Zeichenketten, in der Daten für abcd1-5 gesammelt werden.\n",
    "abcd1 = \"\"\n",
    "abcd2 = \"\"\n",
    "abcd3 = \"\"\n",
    "abcd4 = \"\"\n",
    "abcd5 = \"\"\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#21 Einlesen der CSV-Datei in ein DataFrame.\n",
    "df = pd.read_csv('text.csv', encoding='utf-8')\n",
    "#22 Hinzufügen von Daten an abcd1, abcd2, abcd3, abcd4 und abcd5.\n",
    "abcd1 += df.quelle + ',' + df.labela + ':' + df.labelb1 + ':' + df.labelc1 + ',' + df.inhalt + ',0'\n",
    "abcd2 += df.quelle + ',' + df.labela + ':' + df.labelb2 + ':' + df.labelc2 + ',' + df.inhalt + ',0'\n",
    "abcd3 += df.quelle + ',' + df.labela + ':' + df.labelb3 + ':' + df.labelc3 + ',' + df.inhalt + ',0'\n",
    "abcd4 += df.quelle + ',' + df.labela + ':' + df.labelb4 + ':' + df.labelc4 + ',' + df.inhalt + ',0'\n",
    "abcd5 += df.quelle + ',' + df.labela + ':' + df.labelb5 + ':' + df.labelc5 + ',' + df.inhalt + ',0'\n",
    "#23 Zusammenstellen der Daten aus abcd1 bis abcd5.\n",
    "recorded = (abcd1 + '\\n' + abcd2 + '\\n' + abcd3 + '\\n' + abcd4 + '\\n' + abcd5 + '\\n')\n",
    "#24 Schreiben der aufgezeichneten Daten in eine CSV-Datei.\n",
    "with open(\"text_aw.csv\", 'w', encoding='utf-8') as w:\n",
    "    w.write('quelle,index_string,inhalt,index_binar\\n')\n",
    "    w.write('000:ballast,ballast,ballast,0\\n')  #25 Schreiben einer Platzhalterzeile.\n",
    "    w.write(\"\".join(recorded))  #26 Schreiben der aufgezeichneten Daten.\n",
    "import csv\n",
    "mom = []  #27 Eine leere Liste zum Speichern der Daten.\n",
    "\n",
    "#28 Lesen der CSV-Datei und Filtern von Zeilen mit ':N:' in der zweiten Spalte.\n",
    "with open('text_aw.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        if ':N:' not in line[1]:  #29 Wenn ':N:' nicht in der zweiten Spalte enthalten ist.\n",
    "            mom.append(line)  #30 Die Zeile der Liste mom hinzufügen.\n",
    "#31 Schreiben der gefilterten Daten in eine Textdatei.\n",
    "with open('text_ax.txt', 'wt', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(mom)  #32 Schreiben der Liste in die Datei.\n",
    "#33 Lesen der Textdatei und Formatieren der Daten.\n",
    "with open('text_ax.txt', 'r', encoding='utf-8') as file:\n",
    "    filedata = file.read()\n",
    "filedata = (filedata.replace(']\",\"[', \"\\n\").replace('\"[', '').replace(']\"', '').replace(\" '\", \"\")\n",
    "            .replace(\"'\", \"\"))\n",
    "#34 Schreiben der formatierten Daten in eine CSV-Datei.\n",
    "with open('text_ay.csv', 'w', encoding='utf-8') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Datei zum Lesen und Schreiben festlegen\n",
    "input_file = 'text_ay.csv'   # Pfad zur Eingabedatei\n",
    "output_file = 'text_ay_mudi.csv'  # Pfad zur Ausgabedatei\n",
    "\n",
    "# Funktion, um das vierte Segment im Feld index_string zu entfernen\n",
    "def remove_fourth_segment(index_string):\n",
    "    segments = index_string.split(':')\n",
    "    if len(segments) > 3:\n",
    "        del segments[3]  # Entfernt das vierte Segment\n",
    "    return ':'.join(segments)\n",
    "\n",
    "# CSV-Datei lesen und bearbeiten\n",
    "with open(input_file, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    fieldnames = reader.fieldnames  # Spaltennamen speichern\n",
    "\n",
    "    # Bearbeitete Daten schreiben\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as csvfile_out:\n",
    "        writer = csv.DictWriter(csvfile_out, fieldnames=fieldnames)\n",
    "        writer.writeheader()  # Kopfzeile schreiben\n",
    "        \n",
    "        for row in reader:\n",
    "            # Feld 'index_string' bearbeiten\n",
    "            row['index_string'] = remove_fourth_segment(row['index_string'])\n",
    "            writer.writerow(row)  # Geänderte Zeile schreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Datei text_ay_mudi.csv wurde erfolgreich bearbeitet und gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "# Pfad zur CSV-Datei\n",
    "csv_datei = 'text_ay_mudi.csv'\n",
    "\n",
    "# Datenstruktur zum Speichern der Häufigkeit der Kombinationen\n",
    "kombinationen = defaultdict(int)\n",
    "\n",
    "# Die CSV-Datei lesen und die Häufigkeit der Kombinationen zählen\n",
    "with open(csv_datei, mode='r', newline='', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    rows = list(reader)\n",
    "\n",
    "    # Zählen der Häufigkeit jeder Kombination\n",
    "    for row in rows:\n",
    "        kombination = (row['quelle'], row['index_string'])\n",
    "        kombinationen[kombination] += 1\n",
    "\n",
    "# Die Kombinationen-Häufigkeiten zurücksetzen, um die Bearbeitung durchzuführen\n",
    "kombinationen = defaultdict(int)\n",
    "\n",
    "# Die CSV-Datei bearbeiten, wobei wiederholte Kombinationen entsprechend der Häufigkeit 'x' erhalten\n",
    "for row in rows:\n",
    "    kombination = (row['quelle'], row['index_string'])\n",
    "    kombinationen[kombination] += 1\n",
    "    if kombinationen[kombination] > 1:\n",
    "        # Hängt entsprechend der Wiederholung so viele '_x' an\n",
    "        row['index_string'] += '_x' * (kombinationen[kombination] - 1) #alternativ gilt für mehrmalige '_x' \n",
    "        #row['index_string'] += '_x' #alternativ gilt für einmalige '_x' \n",
    "\n",
    "# Die bearbeitete CSV-Datei unter demselben Namen speichern\n",
    "with open(csv_datei, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=rows[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Die Datei {csv_datei} wurde erfolgreich bearbeitet und gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from collections import Counter \n",
    "df = pd.read_csv('text_ay_mudi.csv', encoding='utf-8')  #35 Einlesen der Daten aus einer CSV-Datei in ein DataFrame.\n",
    "#36 Eine Funktion zur Formatierung der Markupelemente eines Märchens.\n",
    "def ep_format(ep_full):\n",
    "    return (ep_full.split(':'))[0]\n",
    "#37 Eine Funktion zur Formatierung des Typs eines Märchens.\n",
    "def ep_name_format(ep_full):\n",
    "    sublist = (ep_full)\n",
    "    name = \"\"\n",
    "    for strg in sublist:\n",
    "        name += strg\n",
    "    return name\n",
    "#38 Eine Funktion zum Vergleich von Quellen in einem DataFrame.\n",
    "def quellenvergleich(df, i1, i2):\n",
    "    return df.quelle[i1] == df.quelle[i2]\n",
    "#39 Eine Funktion zur Analyse von Abschnitten eines Märchens.\n",
    "def ast(gesep, df):\n",
    "    ep_tree = {}  #40 Ein leeres Dictionary zur Speicherung der Analyseergebnisse.\n",
    "    a_liste = []  #41 Eine leere Liste zur Speicherung von Startabschnitten.\n",
    "    z_liste = []  #42 Eine leere Liste zur Speicherung von Endabschnitten.\n",
    "    df_len = len(df.index_string)  # Die Anzahl der Zeilen im DataFrame.\n",
    "    for i, ep in enumerate(df.index_string):  #43 Iteration durch die 'Index-String' des DataFrames.\n",
    "        if gesep == ep:  #44 Wenn der aktuelle Abschnitt dem gesuchten Abschnitt entspricht.\n",
    "            if (i > 0) and (quellenvergleich(df, i, i - 1)):  #45 Wenn es einen vorherigen Abschnitt gibt und die Quellen übereinstimmen.\n",
    "                a = df.index_string[i - 1]  #46 Der vorherige Abschnitt wird als Startabschnitt betrachtet.\n",
    "            else:\n",
    "                a = 'Anf-' + ep_name_format(gesep)  #47 Ansonsten wird ein neuer Startabschnitt erstellt.\n",
    "            if (i < df_len - 1):  #48 Wenn es einen nächsten Abschnitt gibt.\n",
    "                if not (quellenvergleich(df, i, i + 1)):  #49 Wenn die Quellen des nächsten Abschnitts unterschiedlich sind.\n",
    "                    z = 'End-' + ep_name_format(gesep)  #50 Der aktuelle Abschnitt wird als Endabschnitt betrachtet.\n",
    "                else:\n",
    "                    z = df.index_string[i + 1]  #51 Ansonsten wird der nächste Abschnitt als Endabschnitt betrachtet.\n",
    "            else:\n",
    "                z = 'End-' + ep_name_format(gesep)  #52 Wenn es keinen nächsten Abschnitt gibt, wird ein neuer Endabschnitt erstellt.\n",
    "            a_liste.append(a)  #53 Startabschnitt wird der Liste hinzugefügt.\n",
    "            z_liste.append(z)  #54 Endabschnitt wird der Liste hinzugefügt.\n",
    "    return {gesep: [Counter(a_liste), Counter(z_liste)]}  #55 Rückgabe der Analyseergebnisse als Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alle_aeste(gesep, df):\n",
    "    episoden_baeume = {}  #56 Ein leeres Dictionary zur Speicherung der Analyseergebnisse.\n",
    "    ep_list = []  #57 Eine leere Liste zur Speicherung von Episoden.\n",
    "    for ep_full in df.index_string:  #58 Iteration durch die 'Index-String' des DataFrames.\n",
    "        ep = ep_format(ep_full)  #59 Formatierung der Episode.\n",
    "        if gesep == ep:  #60 Wenn die gesuchte Episode gefunden wird.\n",
    "            ep_list.append(ep_full)  #61 Die Episode wird zur Liste hinzugefügt.\n",
    "    for ep in set(ep_list):  #62 Iteration durch jede einzigartige Episode in der Liste.\n",
    "        episoden_baeume.update(ast(ep, df))  #63 Die Analyseergebnisse für jede Episode werden dem Dictionary hinzugefügt.\n",
    "    return episoden_baeume  #64 Rückgabe des Dictionary mit den Analyseergebnissen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#63 Die Variable 'graph' wird mit den Analyseergebnissen für die Episode 'mZahl' initialisiert.\n",
    "graph = alle_aeste(mZahl, df)\n",
    "graph_update()\n",
    "#wald_printer(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:31.249124Z",
     "start_time": "2024-01-25T21:11:30.925952Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import networkx as nx \n",
    "#66 Eine Funktion zum Filtern von Daten für einen bestimmten Ast.\n",
    "def cutoff_ast_data(wuerzel, graph, nachbar_liste, cutoff=0):\n",
    "    vor = graph[wuerzel][0]  #67 Vorwärtsverbindungen des Astes.\n",
    "    zurueck = graph[wuerzel][1]  #68 Rückwärtsverbindungen des Astes.\n",
    "    nachbarn = vor.copy()  #69 Kopie der Vorwärtsverbindungen.\n",
    "    nachbarn.update(zurueck)  #70 Hinzufügen der Rückwärtsverbindungen.\n",
    "    for ast_name, ast_gewicht in sorted(nachbarn.items()):  #71 Iteration durch die Nachbarn des Astes.\n",
    "        if (ast_gewicht >= cutoff):  #72 Wenn das Gewicht größer oder gleich dem Cutoff-Wert ist.\n",
    "            nachbar_liste.append([ep_name_format(wuerzel),\n",
    "                                   ep_name_format(ast_name), ast_gewicht])  #73 Die Verbindung wird der Nachbarliste hinzugefügt.\n",
    "#74 Eine Funktion zum Filtern von Daten für den gesamten Graphen.\n",
    "def cutoff_graph_data(graph, cutoff=0):\n",
    "    nachbar_liste = []  #75 Eine leere Liste zur Speicherung der Nachbarn.\n",
    "    for i, (k, v) in enumerate(sorted(graph.items())):  #76 Iteration durch die Elemente des Graphen.\n",
    "        cutoff_ast_data(k, graph, nachbar_liste, cutoff)  #77 Filtern der Daten für jeden Ast.\n",
    "    neue_nachbar_liste = [[i, nachbar] for i, nachbar in enumerate(nachbar_liste)]  #78 Indexierung der Nachbarn.\n",
    "    return neue_nachbar_liste  #79 Rückgabe der gefilterten Nachbardaten.\n",
    "#80 Eine Funktion zur Aktualisierung der interaktiven Daten des Graphen.\n",
    "def interactive_graph_data(graph_data, loesch_index, gew_dict):\n",
    "    for k, v in gew_dict.items():  #81 Iteration durch die Gewichts-Daten.\n",
    "        graph_data[k][1][2] = v  #82 Aktualisieren der Gewichts-Daten.\n",
    "    neue_nachbar_liste = [[i, nachbar[1]] for i,\n",
    "                          nachbar in enumerate(graph_data) if i not in loesch_index]  #83 Filtern der Daten.\n",
    "    return neue_nachbar_liste  #84 Rückgabe der aktualisierten Daten.\n",
    "\n",
    "#85 Eine Funktion zum Aufbau des Graphen aus den Daten.\n",
    "def graph_bauer(graph_data):\n",
    "    G = nx.Graph()  #86 Initialisierung eines gerichteten Graphen.\n",
    "    w_liste = []  #87 Eine leere Liste zur Speicherung der Gewichts-Daten.\n",
    "    for el in graph_data:  #88 Iteration durch die Elemente der Graphendaten.\n",
    "        n1 = el[1][0]  #89 Der Ausgangsknoten der Verbindung.\n",
    "        n2 = el[1][1]  #90 Der Zielknoten der Verbindung.\n",
    "        w = el[1][2]  #91 Das Gewicht der Verbindung.\n",
    "        w_liste.append(w)  #92 Hinzufügen des Gewichts zur Liste.\n",
    "        #93 Hinzufügen der Verbindung und der Knoten zum Graphen.\n",
    "        G.add_edge(n1, n2, weight=w, title=w)\n",
    "        G.add_edge(n1, n2, weight=w, title=w)\n",
    "        G.add_node(n1, title=n1, size=15)\n",
    "        G.add_node(n2, title=n2, size=15)\n",
    "    return G, w_liste  #94 Rückgabe des Graphen und der Gewichtsliste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#95 Filtern der Graphendaten basierend auf der Häufigkeit.\n",
    "auto_graph = cutoff_graph_data(graph, haeufigkeit)\n",
    "G, W = graph_bauer(auto_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:12:53.897428Z",
     "start_time": "2024-01-25T21:12:53.677815Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network \n",
    "#96 Erstellen des Graphen und der Gewichtsliste aus den Graphendaten.\n",
    "G, W = graph_bauer(auto_graph)\n",
    "\n",
    "#97 Erstellen einer Network-Instanz für die Visualisierung des Graphen.\n",
    "nt = Network(notebook=True,  #98 Das Netzwerk wird im Jupyter Notebook angezeigt.\n",
    "             height='650px',  #99 Höhe des Netzwerks.\n",
    "             width='1300px',  #100 Breite des Netzwerks.\n",
    "             directed=False,  #101 Der Graph ist ungerichtet.\n",
    "             neighborhood_highlight=True,\n",
    "             bgcolor='#ffffff',  #102 Hintergrundfarbe des Netzwerks.\n",
    "             font_color='black',  #103 Die Farbe der Schrift im Netzwerk wird automatisch festgelegt.\n",
    "             layout=None,  #104 Die Layout-Eigenschaft wird nicht gesetzt (standardmäßig wird ein Fruchterman-Reingold-Layout verwendet).\n",
    "             heading='',  #105 Ein leerer Titel für das Netzwerk.\n",
    "             filter_menu=True,\n",
    "             select_menu=True,\n",
    "             cdn_resources='in_line')  #106 Die Ressourcen werden lokal geladen (ohne Internetverbindung).\n",
    "#107 Fügen Sie die Knoten und Kanten des Graphen zur Netzwerkinstanz hinzu.\n",
    "nt.from_nx(G)\n",
    "\n",
    "#108 Anzeigen des Netzwerks im Jupyter Notebook.\n",
    "with open('nx_22.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(nt.generate_html())  # Erzeugt HTML mit UTF-8 Unterstützung\n",
    "#nt.show('nx.html')  #109 Die Visualisierung wird in einer HTML-Datei gespeichert und im Notebook angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv  \n",
    "import numpy as np \n",
    "#110 Eine Funktion zur Überprüfung, ob ein Nachbar in einen Knoten einbezogen werden kann.\n",
    "def neighbour_is_includable(node, neighbour):\n",
    "    designation = \":\".join(node.split(\":\")[0:1])  #111 Extrahieren der Bezeichnung des Knotens.\n",
    "    return neighbour.startswith(designation)  #112 Rückgabe, ob der Nachbar in den Knoten einbezogen werden kann.\n",
    "#113 Eine Funktion zur Bereinigung der Kanten basierend auf der Einbeziehbarkeit.\n",
    "def pruned_edges(node, neighbours):\n",
    "    return [neighbor for neighbor in neighbours if neighbour_is_includable(node, neighbor)]\n",
    "#114 Eine Funktion zur Erstellung eines bereinigten Graphen.\n",
    "def make_pruned_graph(graph):\n",
    "    pruned_graph = {}\n",
    "    for node, (incoming, outgoing) in graph.items():\n",
    "        pruned_incoming = pruned_edges(node, incoming)\n",
    "        pruned_outgoing = pruned_edges(node, outgoing)\n",
    "        pruned_graph[node] = (pruned_incoming, pruned_outgoing)\n",
    "    return pruned_graph\n",
    "#115 Eine Funktion zur Erstellung eines gerichteten Rückgrat-Graphen.\n",
    "def make_backbone_di_graph(pruned_graph):\n",
    "    new_DiGraph = nx.DiGraph()\n",
    "    for node, (incoming, outgoing) in pruned_graph.items():\n",
    "        for in_node in incoming:\n",
    "            new_DiGraph.add_edge(in_node, node)\n",
    "        for out_node in outgoing:\n",
    "            new_DiGraph.add_edge(node, out_node)\n",
    "    return new_DiGraph\n",
    "#116 Eine Funktion zur Berechnung der kürzesten Pfade mit Vorzeichen.\n",
    "def signed_shortest_path_length(G, source, target):\n",
    "    try:\n",
    "        pl = nx.dijkstra_path_length(G, source=source, target=target)\n",
    "    except nx.NodeNotFound:\n",
    "        pl = np.Inf\n",
    "    except nx.NetworkXNoPath:\n",
    "        try:\n",
    "            pl = - nx.dijkstra_path_length(G, source=target, target=source)\n",
    "        except nx.NodeNotFound:\n",
    "            pl = np.Inf\n",
    "        except nx.NetworkXNoPath:\n",
    "            pl = np.Inf\n",
    "    return pl\n",
    "#117 Eine Funktion zur Erstellung von Distanzdaten für Hauptknoten.\n",
    "def create_main_node_distances(start_node, pruned_graph, graph, nx_graph):\n",
    "    distances = { key:[] for key in graph}\n",
    "    backbone_di_graph= make_backbone_di_graph(pruned_graph)\n",
    "    for node in pruned_graph:\n",
    "        distances[node] = {signed_shortest_path_length(backbone_di_graph, start_node, node)}\n",
    "    return distances\n",
    "#118 Eine Funktion zum Hinzufügen von Distanzdaten für Unter- bzw. Nebenknoten.\n",
    "def add_sub_node_distances(node, sub_nodes, pruned_graph, distances, d):\n",
    "    for sub_node in sub_nodes:\n",
    "        if sub_node not in pruned_graph.keys():\n",
    "            if sub_node not in distances:\n",
    "                distances[sub_node] = set()\n",
    "            new_dists = {dist + d for dist in distances[node]}\n",
    "            distances[sub_node].update(new_dists)\n",
    "#119 Eine Funktion zur Erstellung eines Distanz-Dictionarys.\n",
    "def create_distance_dict(start_node, graph, G):\n",
    "    pruned_graph = make_pruned_graph(graph)\n",
    "    distances = create_main_node_distances(start_node, pruned_graph, graph, G)\n",
    "    for node, (incoming, outgoing) in graph.items():\n",
    "        add_sub_node_distances(node, incoming, pruned_graph, distances, -1)\n",
    "        add_sub_node_distances(node, outgoing, pruned_graph, distances, 1)\n",
    "    return distances\n",
    "#120 Startknoten für die Berechnung der Distanzen.\n",
    "start_node = mWert\n",
    "#121 Erstellen der Distanzdaten.\n",
    "distances = create_distance_dict(start_node, graph, G)\n",
    "#122 Sortieren der Distanzdaten nach den minimalen Distanzen.\n",
    "sorted_keys = sorted(distances, key=lambda x: min(distances[x]))\n",
    "sorted_distances = {key: distances[key] for key in sorted_keys}\n",
    "#123 Konvertierung der Distanzdaten in eine Zeichenfolge für den HTML-Output.\n",
    "msia=\"\"\n",
    "tai = []\n",
    "for k, v in sorted_distances.items():\n",
    "    sia=(f\"{k} {v}\")\n",
    "    msia+=sia+'<br>'\n",
    "    tai.append(sia)\n",
    "    #print(sia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#124 Pfad zur CSV-Datei\n",
    "csv_file_path = 'output_1.csv'\n",
    "#125 Schreibe die Daten in die CSV-Datei\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')  \n",
    "    #126 Schreibe die Überschrift (Header) in die CSV-Datei\n",
    "    writer.writerow(['Data'])\n",
    "    #127 Schreibe die Zeilen in die CSV-Datei\n",
    "    for data in tai:\n",
    "        writer.writerow([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#128 Diese Funktion erstellt eine Menge aus den ausgewählten Knoten basierend auf den Kanten im Graphen.\n",
    "def make_set_of_chosen_vertices(graph_edge_data):\n",
    "    chosen_vertices = set()  #129 Initialisierung einer leeren Menge für ausgewählte Knoten\n",
    "    for sub_list in graph_edge_data:  #130 Iteration durch die Kanten im Graphen\n",
    "        sub_sub_list = sub_list[1]  #131 Die Kanteninformationen befinden sich in der zweiten Unterliste\n",
    "        chosen_vertices.add(sub_sub_list[0])  #132 Hinzufügen des ersten Knotens der Kante zur Menge ausgewählter Knoten\n",
    "        chosen_vertices.add(sub_sub_list[1])  #133 Hinzufügen des zweiten Knotens der Kante zur Menge ausgewählter Knoten\n",
    "    return chosen_vertices  #134 Rückgabe der Menge ausgewählter Knoten\n",
    "\n",
    "dat = []  #135 Initialisierung einer leeren Liste 'dat' für Daten\n",
    "\n",
    "#136 'graph_data' enthält die Informationen über die Kanten im Graphen, basierend auf einer bestimmten Häufigkeitsschwelle ('haeufigkeit')\n",
    "graph_data = cutoff_graph_data(graph, haeufigkeit)\n",
    "\n",
    "#137 Die ausgewählten Knoten werden aus der Menge ausgewählt und sortiert\n",
    "chosen_vertices = list(make_set_of_chosen_vertices(graph_data))  \n",
    "#chosen_vertices.sort()  \n",
    "\n",
    "#138 Iteration durch die ausgewählten Knoten\n",
    "for vertex_name in chosen_vertices:\n",
    "    dat.append(vertex_name)  # Hinzufügen des Knotennamens zur Liste 'dat'\n",
    "csv_file_path = 'output_2.csv'\n",
    "#139 Schreibe die Daten in die CSV-Datei\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')    \n",
    "    #140 Schreibe die Überschrift (Header) in die CSV-Datei\n",
    "    writer.writerow([''])\n",
    "    #141 Schreibe die Zeilen in die CSV-Datei\n",
    "    for data in dat:\n",
    "        writer.writerow([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ = a1920F\n",
      "Referenz-Motiv = a1633:h:Tod_von_Angehörigen\n",
      "Häufigkeit = 1\n",
      "\n",
      "Anf-a1633:h:Tod_von_Angehörigen {-1}\n",
      "a1633:h:Tod_von_Angehörigen {0}\n",
      "a1633:h:Wahl_als_ABSURDITÄT {1}\n",
      "a1633:h:Wahl_als_ABSURDITÄT_x {2}\n",
      "a1633:H:ABSURDITÄT_entgegentreten {3}\n",
      "a1633:h:ABSURDITÄT_nachgehen {4}\n",
      "a1633:H:ABSURDITÄT_nachgehen {5}\n",
      "a1633:h:KONTAKT_abbrechen {6}\n",
      "a1633:h:Ortswechsel_durchführen {7}\n",
      "a1633:f:WETTKAMPF {8}\n",
      "a1633:h:WETTKAMPF_in_Angriff_nehmen {9}\n",
      "a1633:h:VERSCHLINGEN {10}\n",
      "a1633:h:KONTAKT_abbrechen_x {11}\n",
      "a1633:h:Ortswechsel_durchführen_x {12}\n",
      "a1633:f:WETTKAMPF_x {13}\n",
      "a1633:h:WETTKAMPF_in_Angriff_nehmen_x {14}\n",
      "a1633:h:VERSCHLINGEN_x {15}\n",
      "a1633:H:Ortswechsel_durchführen {16}\n",
      "a1633:F:WETTKAMPF {17}\n",
      "a1633:H:WETTKAMPF_in_Angriff_nehmen {18}\n",
      "a1920F:H:WETTKAMPF {inf}\n",
      "a1920F:H:VERSCHLINGEN_beheben {inf}\n",
      "a1920F:H:ERZÄHLEN_beenden {inf}\n",
      "a1920F:F:Um_einen_Auftrag_werben {inf}\n",
      "a1920F:f:WETTKAMPF {inf}\n",
      "a1920F:H:Bestrafung_erfolgt {inf}\n",
      "a1633:H:Ende {inf}\n",
      "a1960:H:ERZÄHLEN_beginnen_x {inf}\n",
      "a1960:h:ERZÄHLEN_beenden_x {inf}\n",
      "a1960:h:ERZÄHLEN_beenden {inf}\n",
      "a1960:F:ERZÄHLEN_beginnen_x {inf}\n",
      "a1960:H:ERZÄHLEN_beginnen {inf}\n",
      "a1960:F:ERZÄHLEN_beginnen {inf}\n",
      "a1960:F:ERZÄHLEN_beenden {inf}\n",
      "Anf-a1920F:f:WETTKAMPF {inf}\n",
      "End-a1633:H:Ende {inf}\n",
      "a1920:F:ERZÄHLEN_beginnen {inf}\n"
     ]
    }
   ],
   "source": [
    "#142 Liste a\n",
    "sia_a=[]\n",
    "with open('output_1.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f) \n",
    "    for line in reader:\n",
    "            sia_a.append(line)\n",
    "#143 Liste b\n",
    "sia_b=[]         \n",
    "with open('output_2.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f) \n",
    "    for line in reader:\n",
    "            sia_b.append(line)\n",
    "#144 Liste c\n",
    "sia_c=[]\n",
    "#145 Iteriere durch Liste a\n",
    "for element_a in sia_a:\n",
    "    #146 Extrahiere den linken String aus dem ersten Element in Liste a\n",
    "    left_string_a = element_a[0].split(' ')[0]\n",
    "\n",
    "    #147 Überprüfe, ob der linke String aus Liste a in Liste b vorhanden ist\n",
    "    if any(left_string_a in element_b[0] for element_b in sia_b):\n",
    "        #148 Wenn ja, füge das aktuelle Element aus Liste a zu Liste c hinzu\n",
    "        sia_c.append(element_a[0])\n",
    "#149 Ausgabe der generierten Liste c\n",
    "print(f'Typ = {mZahl}\\nReferenz-Motiv = {mWert}\\nHäufigkeit = {haeufigkeit}\\n')\n",
    "for element_c in sia_c:\n",
    "    print(element_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nt.from_nx(G)  #150 Konvertiere den Network X-Graphen G in ein pyvis-Network-Objekt\n",
    "# print(f'Typ: {mZahl}\\nMotiv: {mWert}\\nHäufigkeit: {haeufigkeit}')  #151 Gib Informationen über den Graphen aus\n",
    "# nt.show('nx.html')  #152 Speichere die Visualisierung als HTML-Datei und zeige sie an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
